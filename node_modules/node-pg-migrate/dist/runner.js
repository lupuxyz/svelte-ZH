"use strict";

function _slicedToArray(arr, i) { return _arrayWithHoles(arr) || _iterableToArrayLimit(arr, i) || _nonIterableRest(); }

function _nonIterableRest() { throw new TypeError("Invalid attempt to destructure non-iterable instance"); }

function _iterableToArrayLimit(arr, i) { var _arr = []; var _n = true; var _d = false; var _e = undefined; try { for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) { _arr.push(_s.value); if (i && _arr.length === i) break; } } catch (err) { _d = true; _e = err; } finally { try { if (!_n && _i["return"] != null) _i["return"](); } finally { if (_d) throw _e; } } return _arr; }

function _arrayWithHoles(arr) { if (Array.isArray(arr)) return arr; }

function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }

function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(source, true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(source).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

function asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) { try { var info = gen[key](arg); var value = info.value; } catch (error) { reject(error); return; } if (info.done) { resolve(value); } else { Promise.resolve(value).then(_next, _throw); } }

function _asyncToGenerator(fn) { return function () { var self = this, args = arguments; return new Promise(function (resolve, reject) { var gen = fn.apply(self, args); function _next(value) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "next", value); } function _throw(err) { asyncGeneratorStep(gen, resolve, reject, _next, _throw, "throw", err); } _next(undefined); }); }; }

const path = require("path");

const fs = require("fs");

const Db = require("./db");

const Migration = require("./migration");

const _require = require("./utils"),
      getSchemas = _require.getSchemas,
      getMigrationTableSchema = _require.getMigrationTableSchema,
      template = _require.template,
      promisify = _require.promisify,
      PgLiteral = _require.PgLiteral; // Random but well-known identifier shared by all instances of node-pg-migrate


const PG_MIGRATE_LOCK_ID = 7241865325823964;
const readFile = promisify(fs.readFile); // eslint-disable-line security/detect-non-literal-fs-filename

const idColumn = "id";
const nameColumn = "name";
const runOnColumn = "run_on";

const loadMigrations =
/*#__PURE__*/
function () {
  var _ref = _asyncToGenerator(function* (db, options, log) {
    try {
      let shorthands = {};
      const files = yield Migration.loadMigrationFiles(options.dir, options.ignorePattern);
      return files.map(file => {
        const filePath = `${options.dir}/${file}`;
        const actions = path.extname(filePath) === ".sql" ? // eslint-disable-next-line security/detect-non-literal-fs-filename
        {
          up: function () {
            var _up = _asyncToGenerator(function* (pgm) {
              return pgm.sql((yield readFile(filePath, "utf8")));
            });

            function up(_x4) {
              return _up.apply(this, arguments);
            }

            return up;
          }()
        } : // eslint-disable-next-line global-require,import/no-dynamic-require,security/detect-non-literal-require
        require(path.relative(__dirname, filePath));
        shorthands = _objectSpread({}, shorthands, {}, actions.shorthands);
        return new Migration(db, filePath, actions, options, _objectSpread({}, shorthands), log);
      });
    } catch (err) {
      throw new Error(`Can't get migration files: ${err.stack}`);
    }
  });

  return function loadMigrations(_x, _x2, _x3) {
    return _ref.apply(this, arguments);
  };
}();

const lock =
/*#__PURE__*/
function () {
  var _ref2 = _asyncToGenerator(function* (db) {
    const _ref3 = yield db.query(`select pg_try_advisory_lock(${PG_MIGRATE_LOCK_ID}) as "lockObtained"`),
          _ref3$rows = _slicedToArray(_ref3.rows, 1),
          lockObtained = _ref3$rows[0];

    if (!lockObtained) {
      throw new Error("Another migration is already running");
    }
  });

  return function lock(_x5) {
    return _ref2.apply(this, arguments);
  };
}();

const ensureMigrationsTable =
/*#__PURE__*/
function () {
  var _ref4 = _asyncToGenerator(function* (db, options) {
    try {
      const schema = getMigrationTableSchema(options);
      const migrationsTable = options.migrationsTable;
      const fullTableName = {
        schema,
        name: migrationsTable
      };
      const migrationTables = yield db.select(`SELECT table_name FROM information_schema.tables WHERE table_schema = '${schema}' AND table_name = '${migrationsTable}'`);

      if (migrationTables && migrationTables.length === 1) {
        const primaryKeyConstraints = yield db.select(`SELECT constraint_name FROM information_schema.table_constraints WHERE table_schema = '${schema}' AND table_name = '${migrationsTable}' AND constraint_type = 'PRIMARY KEY'`);

        if (!primaryKeyConstraints || primaryKeyConstraints.length !== 1) {
          yield db.query(template`ALTER TABLE "${fullTableName}" ADD PRIMARY KEY (${idColumn})`);
        }
      } else {
        yield db.query(template`CREATE TABLE "${fullTableName}" ( ${idColumn} SERIAL PRIMARY KEY, ${nameColumn} varchar(255) NOT NULL, ${runOnColumn} timestamp NOT NULL)`);
      }
    } catch (err) {
      throw new Error(`Unable to ensure migrations table: ${err.stack}`);
    }
  });

  return function ensureMigrationsTable(_x6, _x7) {
    return _ref4.apply(this, arguments);
  };
}();

const getRunMigrations =
/*#__PURE__*/
function () {
  var _ref5 = _asyncToGenerator(function* (db, options) {
    const schema = getMigrationTableSchema(options);
    const migrationsTable = options.migrationsTable;
    const fullTableName = {
      schema,
      name: migrationsTable
    };
    return db.column(nameColumn, template`SELECT ${nameColumn} FROM "${fullTableName}" ORDER BY ${runOnColumn}, ${idColumn}`);
  });

  return function getRunMigrations(_x8, _x9) {
    return _ref5.apply(this, arguments);
  };
}();

const getMigrationsToRun = (options, runNames, migrations) => {
  if (options.direction === "down") {
    const downMigrations = runNames.filter(migrationName => !options.file || options.file === migrationName).map(migrationName => migrations.find(({
      name
    }) => name === migrationName) || migrationName);
    const toRun = (options.timestamp ? downMigrations.filter(({
      timestamp
    }) => timestamp >= options.count) : downMigrations.slice(-Math.abs(options.count === undefined ? 1 : options.count))).reverse();
    const deletedMigrations = toRun.filter(migration => typeof migration === "string");

    if (deletedMigrations.length) {
      const deletedMigrationsStr = deletedMigrations.join(", ");
      throw new Error(`Definitions of migrations ${deletedMigrationsStr} have been deleted.`);
    }

    return toRun;
  }

  const upMigrations = migrations.filter(({
    name
  }) => runNames.indexOf(name) < 0 && (!options.file || options.file === name));
  return options.timestamp ? upMigrations.filter(({
    timestamp
  }) => timestamp <= options.count) : upMigrations.slice(0, Math.abs(options.count === undefined ? Infinity : options.count));
};

const checkOrder = (runNames, migrations) => {
  const len = Math.min(runNames.length, migrations.length);

  for (let i = 0; i < len; i += 1) {
    const runName = runNames[i];
    const migrationName = migrations[i].name;

    if (runName !== migrationName) {
      throw new Error(`Not run migration ${migrationName} is preceding already run migration ${runName}`);
    }
  }
};

const runMigrations = (toRun, method, direction) => toRun.reduce((promise, migration) => promise.then(() => migration[method](direction)), Promise.resolve());

const runner =
/*#__PURE__*/
function () {
  var _ref6 = _asyncToGenerator(function* (options) {
    const log = options.log || console.log;
    const db = Db(options.dbClient || options.databaseUrl, log);

    try {
      yield db.createConnection();

      if (options.schema) {
        const schemas = getSchemas(options.schema);

        if (options.createSchema) {
          yield Promise.all(schemas.map(schema => db.query(`CREATE SCHEMA IF NOT EXISTS "${schema}"`)));
        }

        yield db.query(`SET search_path TO ${schemas.map(s => `"${s}"`).join(", ")}`);
      }

      if (options.migrationsSchema && options.createMigrationsSchema) {
        yield db.query(`CREATE SCHEMA IF NOT EXISTS "${options.migrationsSchema}"`);
      }

      yield ensureMigrationsTable(db, options);

      if (!options.noLock) {
        yield lock(db, options);
      }

      const _ref7 = yield Promise.all([loadMigrations(db, options, log), getRunMigrations(db, options)]),
            _ref8 = _slicedToArray(_ref7, 2),
            migrations = _ref8[0],
            runNames = _ref8[1];

      if (options.checkOrder) {
        checkOrder(runNames, migrations);
      }

      const toRun = getMigrationsToRun(options, runNames, migrations);

      if (!toRun.length) {
        log("No migrations to run!");
        return [];
      } // TODO: add some fancy colors to logging


      log("> Migrating files:");
      toRun.forEach(m => {
        log(`> - ${m.name}`);
      });

      if (options.fake) {
        yield runMigrations(toRun, "markAsRun", options.direction);
      } else if (options.singleTransaction) {
        yield db.query("BEGIN");

        try {
          yield runMigrations(toRun, "apply", options.direction);
          yield db.query("COMMIT");
        } catch (err) {
          log("> Rolling back attempted migration ...");
          yield db.query("ROLLBACK");
          throw err;
        }
      } else {
        yield runMigrations(toRun, "apply", options.direction);
      }

      return toRun.map(m => ({
        path: m.path,
        name: m.name,
        timestamp: m.timestamp
      }));
    } finally {
      db.close();
    }
  });

  return function runner(_x10) {
    return _ref6.apply(this, arguments);
  };
}();

runner.default = runner; // workaround for transpilers

runner.PgLiteral = PgLiteral;
runner.Migration = Migration;
module.exports = runner;